"""Exploitability reasoning: structured prompt and Ollama call for per-vulnerability risk adjustment."""

import json
import logging
import time
from typing import TYPE_CHECKING

import httpx

from app.schemas.exploitability import (
    ADJUSTED_RISK_TIER_VALUES,
    AdjustedRiskTier,
    ExploitabilityOutput,
)
from app.services.reasoning import ReasoningServiceError

if TYPE_CHECKING:
    from app.core.config import Settings

logger = logging.getLogger(__name__)


EXPLOITABILITY_PROMPT_TEMPLATE = """You are a security analyst assessing exploitability of a vulnerability. Use only the inputs below.

Inputs:
- vulnerability_summary: {vulnerability_summary}
- cvss_score: {cvss_score}
- repo_context: {repo_context}
- dependency_type: {dependency_type}
- exposure_flags: {exposure_flags}

Consider: base severity (CVSS), whether the dependency is in production path, and exposure (e.g. internet-facing, auth required). Output exactly one JSON object with no other text, no markdown, no code fence.

Required JSON shape:
{{
  "adjusted_risk_tier": "critical" | "high" | "medium" | "low" | "info",
  "reasoning": "1-3 sentences explaining the adjusted tier.",
  "recommended_action": "One concrete action (e.g. patch, isolate, accept risk)."
}}

Output only the JSON object."""


def _build_exploitability_prompt(
    vulnerability_summary: str,
    cvss_score: float,
    repo_context: str,
    dependency_type: str,
    exposure_flags: str,
) -> str:
    """Build the exploitability prompt from the five inputs."""
    return EXPLOITABILITY_PROMPT_TEMPLATE.format(
        vulnerability_summary=vulnerability_summary,
        cvss_score=cvss_score,
        repo_context=repo_context or "n/a",
        dependency_type=dependency_type or "n/a",
        exposure_flags=exposure_flags or "n/a",
    )


def _normalize_adjusted_risk_tier(value: str) -> AdjustedRiskTier:
    """Map model output to a valid AdjustedRiskTier; default to high if unrecognized."""
    if not value or not isinstance(value, str):
        return "high"
    normalized = value.strip().lower()
    if normalized in ADJUSTED_RISK_TIER_VALUES:
        return normalized  # type: ignore[return-value]
    # Fuzzy match common variants
    if normalized in ("crit", "critical"):
        return "critical"
    if normalized in ("med", "medium", "moderate"):
        return "medium"
    if normalized in ("informational", "info"):
        return "info"
    return "high"


async def run_exploitability_reasoning(
    vulnerability_summary: str,
    cvss_score: float,
    repo_context: str,
    dependency_type: str,
    exposure_flags: str,
    settings: "Settings",
) -> ExploitabilityOutput:
    """
    Run exploitability reasoning via Ollama and return structured output.

    Raises ReasoningServiceError on connection failure, timeout, or invalid JSON.
    """
    base_url = settings.OLLAMA_BASE_URL.rstrip("/")
    url = f"{base_url}/api/generate"
    prompt = _build_exploitability_prompt(
        vulnerability_summary=vulnerability_summary,
        cvss_score=cvss_score,
        repo_context=repo_context,
        dependency_type=dependency_type,
        exposure_flags=exposure_flags,
    )
    payload = {
        "model": settings.OLLAMA_MODEL,
        "prompt": prompt,
        "stream": False,
        "format": "json",
    }
    timeout = httpx.Timeout(settings.OLLAMA_REQUEST_TIMEOUT_SEC)
    start = time.perf_counter()

    try:
        async with httpx.AsyncClient(timeout=timeout) as client:
            response = await client.post(url, json=payload)
        elapsed = time.perf_counter() - start
    except httpx.ConnectError as e:
        elapsed = time.perf_counter() - start
        logger.info(
            "LLM exploitability request failed",
            extra={
                "llm_latency_seconds": elapsed,
                "model": settings.OLLAMA_MODEL,
                "call": "exploitability",
                "status": "error",
            },
        )
        raise ReasoningServiceError(
            "Ollama is unreachable. Ensure Ollama is running and OLLAMA_BASE_URL is correct.",
            cause=e,
        ) from e
    except httpx.TimeoutException as e:
        elapsed = time.perf_counter() - start
        logger.info(
            "LLM exploitability request failed",
            extra={
                "llm_latency_seconds": elapsed,
                "model": settings.OLLAMA_MODEL,
                "call": "exploitability",
                "status": "error",
            },
        )
        raise ReasoningServiceError(
            "Ollama request timed out. Try increasing OLLAMA_REQUEST_TIMEOUT_SEC.",
            cause=e,
        ) from e
    except httpx.HTTPError as e:
        elapsed = time.perf_counter() - start
        logger.info(
            "LLM exploitability request failed",
            extra={
                "llm_latency_seconds": elapsed,
                "model": settings.OLLAMA_MODEL,
                "call": "exploitability",
                "status": "error",
            },
        )
        raise ReasoningServiceError(
            "Ollama request failed.",
            cause=e,
        ) from e

    if response.status_code != 200:
        raise ReasoningServiceError(
            f"Ollama returned status {response.status_code}. Check that the model is pulled (e.g. ollama pull {settings.OLLAMA_MODEL})."
        )

    logger.info(
        "LLM exploitability request completed",
        extra={
            "llm_latency_seconds": elapsed,
            "model": settings.OLLAMA_MODEL,
            "call": "exploitability",
        },
    )

    try:
        body = response.json()
    except json.JSONDecodeError as e:
        raise ReasoningServiceError(
            "Ollama response body is not valid JSON.",
            cause=e,
        ) from e

    raw_response = body.get("response")
    if raw_response is None:
        raise ReasoningServiceError(
            "Ollama response missing 'response' field."
        )

    if isinstance(raw_response, str):
        raw_response = raw_response.strip()
        if raw_response.startswith("```"):
            lines = raw_response.split("\n")
            if lines[0].startswith("```"):
                lines = lines[1:]
            if lines and lines[-1].strip() == "```":
                lines = lines[:-1]
            raw_response = "\n".join(lines)
        try:
            parsed = json.loads(raw_response)
        except json.JSONDecodeError as e:
            raise ReasoningServiceError(
                "Invalid JSON from model. The model must respond with only valid JSON.",
                cause=e,
            ) from e
    else:
        parsed = raw_response

    if not isinstance(parsed, dict):
        raise ReasoningServiceError(
            "Model output is not a JSON object."
        )

    # Normalize adjusted_risk_tier so minor wording differences do not fail validation
    tier_raw = parsed.get("adjusted_risk_tier")
    if isinstance(tier_raw, str):
        parsed = {**parsed, "adjusted_risk_tier": _normalize_adjusted_risk_tier(tier_raw)}

    try:
        return ExploitabilityOutput.model_validate(parsed)
    except Exception as e:
        raise ReasoningServiceError(
            "Model output does not match expected schema (adjusted_risk_tier, reasoning, recommended_action).",
            cause=e,
        ) from e
